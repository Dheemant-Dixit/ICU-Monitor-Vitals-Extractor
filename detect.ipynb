{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models.yolov3quad import Darknet\n",
    "from datasets.detection_dataset import load_images\n",
    "from utils.metrics import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = '../data/val_images/'\n",
    "OUT_DIR = 'output_folder'\n",
    "MODEL_CFG = './cfgs/yolov3.cfg'\n",
    "WEIGHTS_PATH = './weights/best.pt'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "IMG_SIZE = 32*19\n",
    "BATCH_SIZE = 1\n",
    "CONF_THRES = 0.1\n",
    "NMS_THRES = 0.2\n",
    "TEXT_OUT = True\n",
    "PLOT_FLAG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm -rf '+OUT_DIR)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "model = Darknet(MODEL_CFG, img_size=32*19)\n",
    "checkpoint = torch.load(WEIGHTS_PATH, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "del checkpoint\n",
    "\n",
    "model.to(DEVICE).eval()\n",
    "classes = ['screen']\n",
    "dataloader = load_images(INP_DIR, BATCH_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "img_detections = []\n",
    "t0 = time.time()\n",
    "for batch_idx, (imgs, paths) in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        preds = model(imgs.to(DEVICE))\n",
    "        preds = preds[preds[:,:,8]>CONF_THRES]\n",
    "        if len(preds)>0:\n",
    "            detections = non_max_suppression(preds.unsqueeze(0), 0.1, NMS_THRES)\n",
    "            img_detections.extend(detections)\n",
    "            img_paths.extend(paths)    \n",
    "    print('Batch %d... (Done %.3f s)' % (batch_idx, time.time() - t0))\n",
    "    t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_box(x, img, color=None, line_thickness=None):  # Plots one bounding box on image img\n",
    "\ttl = line_thickness or round(0.001 * max(img.shape[0:2])) + 1  # line thickness\n",
    "\tcolor = color or [random.randint(0, 255) for _ in range(3)]\n",
    "\tcv2.line(img, (int(x[0]), int(x[1])), (int(x[2]), int(x[3])), color, tl)\n",
    "\tcv2.line(img, (int(x[2]), int(x[3])), (int(x[4]), int(x[5])), color, tl)\n",
    "\tcv2.line(img, (int(x[4]), int(x[5])), (int(x[6]), int(x[7])), color, tl)\n",
    "\tcv2.line(img, (int(x[6]), int(x[7])), (int(x[0]), int(x[1])), color, tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding-box colors\n",
    "color_list = [[random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)] \n",
    "\t    for _ in range(len(classes))]\n",
    "for idx, (path, detections) in enumerate(zip(img_paths, img_detections)):\n",
    "\timg = cv2.imread(path)\n",
    "\t# The amount of padding that was added\n",
    "\tpad_x = max(img.shape[0] - img.shape[1], 0) * (IMG_SIZE / max(img.shape))\n",
    "\tpad_y = max(img.shape[1] - img.shape[0], 0) * (IMG_SIZE / max(img.shape))\n",
    "\t# Image height and width after padding is removed\n",
    "\tunpad_h = IMG_SIZE - pad_y\n",
    "\tunpad_w = IMG_SIZE - pad_x\n",
    "\t# Draw bounding boxes and labels of detections\n",
    "\tif detections is not None:\n",
    "\t\tunique_classes = detections[:, -1].cpu().unique()\n",
    "\t\tbbox_colors = random.sample(color_list, len(unique_classes))\n",
    "\n",
    "\t\t# write results to .txt file\n",
    "\t\tresults_img_path = os.path.join(OUT_DIR, path.split('/')[-1])\n",
    "\t\tresults_txt_path = results_img_path + '.txt'\n",
    "\t\tif os.path.isfile(results_txt_path):\n",
    "\t\t\tos.remove(results_txt_path)\n",
    "\n",
    "\t\tfor i in unique_classes:\n",
    "\t\t\tn = (detections[:, -1].cpu() == i).sum()\n",
    "\t\t\tprint('%g %ss' % (n, classes[int(i)]))\n",
    "\n",
    "\t\tfor P1_x, P1_y, P2_x, P2_y, P3_x, P3_y, P4_x, P4_y, conf, cls_conf, cls_pred in detections:\n",
    "\t\t\tP1_y = max((((P1_y - pad_y // 2) / unpad_h) * img.shape[0]).round().item(), 0)\n",
    "\t\t\tP1_x = max((((P1_x - pad_x // 2) / unpad_w) * img.shape[1]).round().item(), 0)\n",
    "\t\t\tP2_y = max((((P2_y - pad_y // 2) / unpad_h) * img.shape[0]).round().item(), 0)\n",
    "\t\t\tP2_x = max((((P2_x - pad_x // 2) / unpad_w) * img.shape[1]).round().item(), 0)\n",
    "\t\t\tP3_y = max((((P3_y - pad_y // 2) / unpad_h) * img.shape[0]).round().item(), 0)\n",
    "\t\t\tP3_x = max((((P3_x - pad_x // 2) / unpad_w) * img.shape[1]).round().item(), 0)\n",
    "\t\t\tP4_y = max((((P4_y - pad_y // 2) / unpad_h) * img.shape[0]).round().item(), 0)\n",
    "\t\t\tP4_x = max((((P4_x - pad_x // 2) / unpad_w) * img.shape[1]).round().item(), 0)\n",
    "\n",
    "\t\t\t# write to file\n",
    "\t\t\tif TEXT_OUT:\n",
    "\t\t\t\twith open(results_txt_path, 'a') as file:\n",
    "\t\t\t\t\tfile.write(('%g %g %g %g %g %g %g %g %g %g \\n') % (P1_x, P1_y, P2_x, P2_y, P3_x, P3_y, P4_x, P4_y, cls_pred, cls_conf * conf))\n",
    "\t\t\t\n",
    "\t\t\tif PLOT_FLAG:\n",
    "\t\t\t\t# Add the bbox to the plot\n",
    "\t\t\t\tlabel = '%s %.2f' % (classes[int(cls_pred)], conf)\n",
    "\t\t\t\tcolor = bbox_colors[int(np.where(unique_classes == int(cls_pred))[0])]\n",
    "\t\t\t\tplot_one_box([P1_x, P1_y, P2_x, P2_y, P3_x, P3_y, P4_x, P4_y], img, color=color)\n",
    "\n",
    "\t\tcv2.imshow(path.split('/')[-1], img)\n",
    "\t\tcv2.waitKey(0)\n",
    "\t\tcv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16 (default, Jan 17 2023, 16:42:09) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "022b16dda81504ef81b7e3bb798a6e569a46b7a9000fdc854d50f05eaeb2d706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
