{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarim/opt/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets.detection_dataset import *\n",
    "# from utils.metrics import *\n",
    "from models.yolov3quad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "CSV_PATH = '../data/labels.csv'\n",
    "IMG_PATH = '../data/images/'\n",
    "FOLD = 0\n",
    "SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_CFG = './cfgs/yolov3.cfg'\n",
    "RESUME = False\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA, MODEL & OPTIMIZER\n",
    "train_loader = load_images_and_labels(IMG_PATH, CSV_PATH, batch_size=4, img_size=32*19, augment=True)\n",
    "model = Darknet(MODEL_CFG, img_size=32*19)\n",
    "start_epoch = 0\n",
    "best_loss = float('inf')\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "if RESUME:\n",
    "    checkpoint = torch.load('weights/latest.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.to(DEVICE).train()\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "\t\tlr=1e-3, momentum=.9, weight_decay=5e-4)\n",
    "    start_epoch = checkpoint['epoch']+1\n",
    "    if checkpoint['optimizer'] is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        best_loss = checkpoint['best_loss']\n",
    "    del checkpoint\n",
    "else:\n",
    "    if not os.path.isfile('weights/darknet53.conv.74'):\n",
    "        os.system('wget https://pjreddie.com/media/files/darknet53.conv.74 -P weights')\n",
    "    load_weights(model, 'weights/darknet53.conv.74')\n",
    "    model.to(DEVICE).train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, optimizer, epoch, n_classes):\n",
    "    ui = -1\n",
    "    rloss = defaultdict(float)  # running loss\n",
    "    metrics = torch.zeros(3, n_classes)\n",
    "    optimizer.zero_grad()\n",
    "    for i, (imgs, targets) in enumerate(train_loader):\n",
    "        t1 = time.time()\n",
    "        if sum([len(x) for x in targets]) < 1:  # if no targets continue\n",
    "            continue\n",
    "        # SGD burn-in\n",
    "        if (epoch == 0) & (i <= 1000):\n",
    "            lr = 1e-4 * (i / 1000) ** 4\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = lr\n",
    "        # Compute loss, compute gradient, update parameters\n",
    "        loss = model(imgs.to(DEVICE), targets, requestPrecision=True)\n",
    "        loss.backward()\n",
    "        accumulated_batches = 1  # accumulate gradient for 4 batches before stepping optimizer\n",
    "        if ((i+1) % accumulated_batches == 0) or (i == len(train_loader) - 1):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Compute running epoch-means of tracked metrics\n",
    "        ui += 1\n",
    "        metrics += model.losses['metrics']\n",
    "        TP, FP, FN = metrics\n",
    "        for key, val in model.losses.items():\n",
    "            rloss[key] = (rloss[key] * ui + val) / (ui + 1)\n",
    "        # Precision\n",
    "        precision = TP / (TP + FP)\n",
    "        mean_precision = precision\n",
    "        k = (TP + FP) > 0\n",
    "        if k.sum() > 0:\n",
    "            mean_precision = precision[k].mean()\n",
    "        # Recall\n",
    "        recall = TP / (TP + FN)\n",
    "        mean_recall = recall\n",
    "        k = (TP + FN) > 0\n",
    "        if k.sum() > 0:\n",
    "            mean_recall = recall[k].mean()\n",
    "        s = ('%11s%11s' + '%11.3g' * 10) % (\n",
    "            '%g/%g' % (epoch, EPOCHS - 1), '%g/%g' % (i, len(train_loader) - 1), rloss['conf'], rloss['cls'],\n",
    "            rloss['loss'], mean_precision, mean_recall, model.losses['nT'], model.losses['TP'],\n",
    "            model.losses['FP'], model.losses['FN'], time.time() - t1)\n",
    "        print(s)\n",
    "    return s, rloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Epoch      Batch       conf        cls       loss          P          R   nTargets         TP         FP         FN       time\n",
      "       0/99      0/499         14          0       20.4          0        nan          4          0    4.9e+04          0       28.8\n",
      "       0/99      1/499         14          0       20.7          0        nan          4          0   4.88e+04          0       28.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m lr \u001b[39m=\u001b[39m epoch_to_lr\u001b[39m.\u001b[39mget(\u001b[39mnext\u001b[39m(k \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m epoch_to_lr \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m epoch), \u001b[39m1e-6\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m optimizer\u001b[39m.\u001b[39mparam_groups: g[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lr\n\u001b[0;32m---> 15\u001b[0m summary, rloss \u001b[39m=\u001b[39m train_one_epoch(train_loader, model, optimizer, epoch, NUM_CLASSES)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Write epoch results\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mresults.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_loader, model, optimizer, epoch, n_classes)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# Compute loss, compute gradient, update parameters\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m model(imgs\u001b[39m.\u001b[39mto(DEVICE), targets, requestPrecision\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m accumulated_batches \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# accumulate gradient for 4 batches before stepping optimizer\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m ((i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m accumulated_batches \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (i \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(train_loader) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "t0, t1 = time.time(), time.time()\n",
    "mean_recall, mean_precision = 0, 0\n",
    "print('%11s' * 12 % ('Epoch', 'Batch', 'conf', 'cls', 'loss', 'P', 'R', 'nTargets', 'TP', 'FP', 'FN', 'time'))\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    # Update scheduler (manual)  at 0, 54, 61 epochs to 1e-3, 1e-4, 1e-5\n",
    "    epoch_to_lr = {\n",
    "        30: 1e-4, \n",
    "        60: 1e-5, \n",
    "        float('inf'): 1e-6\n",
    "    }\n",
    "    lr = epoch_to_lr.get(next(k for k in epoch_to_lr if k > epoch), 1e-6)\n",
    "    for g in optimizer.param_groups: g['lr'] = lr\n",
    "\n",
    "    summary, rloss = train_one_epoch(train_loader, model, optimizer, epoch, NUM_CLASSES)\n",
    "\n",
    "    # Write epoch results\n",
    "    with open('results.txt', 'a') as file:\n",
    "        file.write(summary + '\\n')\n",
    "    # Update best loss\n",
    "    loss_per_target = rloss['loss'] / rloss['nT']\n",
    "    if loss_per_target < best_loss:\n",
    "        best_loss = loss_per_target\n",
    "    # Save latest checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'best_loss': best_loss,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, 'weights/latest.pt')\n",
    "    # Save best checkpoint\n",
    "    if best_loss == loss_per_target:\n",
    "        os.system('cp weights/latest.pt weights/best.pt')\n",
    "    # Save backup weights every 5 epochs\n",
    "    if (epoch > 0) & (epoch % 20 == 0):\n",
    "        os.system('cp weights/latest.pt weights/backup' + str(epoch) + '.pt')\n",
    "# Save final model\n",
    "dt = time.time() - t0\n",
    "print('Finished %g epochs in %.2fs (%.2fs/epoch)' % (epoch, dt, dt / (epoch + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "022b16dda81504ef81b7e3bb798a6e569a46b7a9000fdc854d50f05eaeb2d706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
